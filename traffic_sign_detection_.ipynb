{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic sign detection .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOR36kGj4Ql8ADWGrXR8vw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunBBB/OMG/blob/main/traffic_sign_detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount (\"./MyDrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fwLyVfVSzZb",
        "outputId": "085c4de6-afa9-4e98-ee28-e62d1fa4f9c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./MyDrive; to attempt to forcibly remount, call drive.mount(\"./MyDrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gdymOEFfay3",
        "outputId": "fda3a615-6187-4b9f-ba17-bdbb3f339bc0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/MyDrive/MyDrive/archive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XylQHx1JTIhX",
        "outputId": "c34c568a-8a7c-4ef6-9394-63549fc6b39d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MyDrive/MyDrive/archive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip installnumpy==1. 19. 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gyYNhGMfiHq",
        "outputId": "994d5f18-ac90-4557-9165-7abc123caa85"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: '19.'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO options\n",
        "YOLO_DARKNET_WEIGHTS        = \"../model_data/yolov3.weights\"\n",
        "YOLO_COCO_CLASSES           = \"../model_data/coco.names\"\n",
        "YOLO_STRIDES                = [8, 16, 32]\n",
        "YOLO_IOU_LOSS_THRESH        = 0.5\n",
        "YOLO_ANCHOR_PER_SCALE       = 3\n",
        "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
        "YOLO_INPUT_SIZE             = 416\n",
        "YOLO_ANCHORS                = [[[10,  13], [16,   30], [33,   23]],\n",
        "                               [[30,  61], [62,   45], [59,  119]],\n",
        "                               [[116, 90], [156, 198], [373, 326]]]\n",
        "# Train options\n",
        "TRAIN_CLASSES               = \"classes.names\"\n",
        "TRAIN_ANNOT_PATH            = \"train.txt\"\n",
        "TRAIN_BATCH_SIZE            = 4\n",
        "TRAIN_INPUT_SIZE            = 416\n",
        "TRAIN_DATA_AUG              = True\n",
        "TRAIN_TRANSFER              = True\n",
        "TRAIN_FROM_CHECKPOINT       = False #\"./checkpoints_furits/yolov3_custom\"\n",
        "\n",
        "TRAIN_LR_INIT               = 1e-4\n",
        "TRAIN_LR_END                = 1e-6\n",
        "TRAIN_WARMUP_EPOCHS         = 2\n",
        "TRAIN_EPOCHS                = 20\n",
        "\n",
        "# TEST options\n",
        "TEST_ANNOT_PATH             = \"test.txt\"\n",
        "TEST_INPUT_SIZE             = 416\n",
        "TEST_DATA_AUG               = False"
      ],
      "metadata": {
        "id": "0TU5ZS51gewU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "class preprocessing:\n",
        "    def __init__(self, resize_size):\n",
        "        self.resize_size = resize_size\n",
        "    \n",
        "    def resize(self, img):\n",
        "        resize_img = cv2.resize(img, (self.resize_size, self.resize_size))\n",
        "        return resize_img\n",
        "    \n",
        "    def normalize_img(self, img):\n",
        "        norm_img = img / 255.0\n",
        "        return norm_img\n",
        "\n",
        "    def label_parsing(self, label_path):\n",
        "        label_data = []\n",
        "        labels_dict = dict(obj_class=[], xmin=[], xmax=[], ymin=[], ymax=[])\n",
        "        with open(label_path, 'r') as f:\n",
        "            labels = f.readlines()\n",
        "            for label in labels:\n",
        "                labels_dict['obj_class'].append(int(label.split()[0]))\n",
        "                center_x = float(label.split()[1])\n",
        "                center_y = float(label.split()[2])\n",
        "                width = float(label.split()[3])\n",
        "                height = float(label.split()[4])\n",
        "                xmin = center_x - (width / 2)\n",
        "                xmax = center_x + (width / 2)\n",
        "                ymin = center_y - (height / 2)\n",
        "                ymax = center_y + (height / 2)\n",
        "                labels_dict['xmin'].append(xmin)\n",
        "                labels_dict['xmax'].append(xmax)\n",
        "                labels_dict['ymin'].append(ymin)\n",
        "                labels_dict['ymax'].append(ymax)\n",
        "            label_data.append(labels_dict)\n",
        "\n",
        "        return label_data\n",
        "def main():\n",
        "    datapath = '/content/MyDrive/MyDrive/archive/ts_data.data'\n",
        "    image_files = glob(os.path.join(datapath, '*.jpg'))\n",
        "    label_files = glob(os.path.join(datapath, '*.txt'))\n",
        "    prepro_img = preprocessing(resize_size=244)\n",
        "\n",
        "    train_data_num = int(len(image_files) * 0.8)\n",
        "    train_img = image_files[:train_data_num]\n",
        "    test_img = image_files[train_data_num:]\n",
        "    for file in image_files:\n",
        "        #print(file)\n",
        "        img = cv2.imread(file)\n",
        "        resize_img = prepro_img.resize(img)\n",
        "        norm_img = prepro_img.normalize_img(resize_img)\n",
        "        a\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "\n",
        "    # # def main():\n",
        "    # datapath = '../ts/ts'\n",
        "    # train_image = []\n",
        "    # train_label = []\n",
        "    # test_image = []\n",
        "    # test_label = []\n",
        "    # with open('../train.txt', 'r') as f:\n",
        "    #     lines = f.readlines()\n",
        "    #     for line in lines:\n",
        "    #         filename = line.split('/')[-1]\n",
        "    #         label_name = filename.replace('.jpg', '.txt').rstrip('\\n')\n",
        "    #         train_image.append(os.path.join(datapath, filename.rstrip('\\n')))\n",
        "    #         train_label.append(os.path.join(datapath, label_name))\n",
        "    \n",
        "    # with open('../test.txt', 'r') as f:\n",
        "    #     lines = f.readlines()\n",
        "    #     for line in lines:\n",
        "    #         filename = line.split('/')[-1]\n",
        "    #         label_name = filename.replace('.jpg', '.txt').rstrip('\\n')\n",
        "    #         test_image.append(os.path.join(datapath, filename.rstrip('\\n')))\n",
        "    #         test_label.append(os.path.join(datapath, label_name))\n",
        "        \n",
        "    # prepro_img = preprocessing(resize_size=244)\n",
        "    \n",
        "    # train_data = list(zip(train_image, train_label))\n",
        "    # random.seed(4)\n",
        "    # random.shuffle(train_data)\n",
        "   \n",
        "    # # check the input images\n",
        "    # for i, file in enumerate(train_data):\n",
        "        \n",
        "    #     image = cv2.imread(file[0])\n",
        "    #     label = prepro_img.label_parsing(file[1])\n",
        "        \n",
        "    #     #resize_img = prepro_img.resize(image)\n",
        "    #     #norm_img = prepro_img.normalize_img(resize_img)\n",
        "    #     if i == 0:\n",
        "    #         print(file)\n",
        "    #         rect_img = image\n",
        "    #         print(str(label[0]['obj_class'][0]))\n",
        "    #         h, w, c = rect_img.shape\n",
        "            \n",
        "    #         for i in range(len(label[0]['obj_class'])):\n",
        "    #             bb_color = (0, 0, 0)\n",
        "    #             if label[0]['obj_class'][i] == 0:\n",
        "    #                 bb_color = (255, 0, 0) # blue: \n",
        "    #             elif label[0]['obj_class'][i] == 1:\n",
        "    #                 bb_color = (0, 255, 0) # green: \n",
        "    #             elif label[0]['obj_class'][i] == 2:\n",
        "    #                 bb_color = (0, 0, 255) # red: \n",
        "    #             elif label[0]['obj_class'][i] == 3:\n",
        "    #                 bb_color = (255, 255, 0) # yello: \n",
        "                \n",
        "    #             print(int(float(label[0]['xmin'][i])*w))\n",
        "    #             print(int(h*float(label[0]['ymin'][i])))\n",
        "    #             rect_img = cv2.rectangle(rect_img, ((int(w*label[0]['xmin'][i])), int(h*label[0]['ymin'][i])), (int(w*label[0]['xmax'][i]), int(h*label[0]['ymax'][i])), bb_color, 1)\n",
        "    #         cv2.imwrite('bb_result.jpg', rect_img)\n",
        "  #  주석으로 해둔 것들이랑 뭔 차이일까용... 이건 어디에다 넣어야 하나요...\n",
        "# 슨상님꺼"
      ],
      "metadata": {
        "id": "qwEZaKuzTT2Q"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_class_names(class_file_name):\n",
        "    # loads class name from a file\n",
        "    #print(class_file_name)\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names\n",
        "\n",
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session()\n",
        "     # used to reset layer names\n",
        "    # load Darknet original weights to Keras model\n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "        \n",
        "        j = 0\n",
        "        for i in range(75):\n",
        "            if i > 0:\n",
        "                conv_layer_name = 'conv2d_%d' %i\n",
        "            else:\n",
        "                conv_layer_name = 'conv2d'\n",
        "                \n",
        "            if j > 0:\n",
        "                bn_layer_name = 'batch_normalization_%d' %j\n",
        "            else:\n",
        "                bn_layer_name = 'batch_normalization'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "                            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n"
      ],
      "metadata": {
        "id": "xG1FZIPf9BgC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes"
      ],
      "metadata": {
        "id": "vJA9wbmumpGe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_iou(boxes1, boxes2):\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area"
      ],
      "metadata": {
        "id": "DqJ1XjQ3m08C"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_giou(boxes1, boxes2):\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou"
      ],
      "metadata": {
        "id": "g6i5QbtHm1VT"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "    # Dataset preprocess implementation\n",
        "    def __init__(self, dataset_type, args):\n",
        "        self.args = args\n",
        "        \n",
        "        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n",
        "        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE\n",
        "        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n",
        "        self.data_aug    = TRAIN_DATA_AUG   if dataset_type == 'train' else TEST_DATA_AUG\n",
        "\n",
        "        self.train_input_sizes = TRAIN_INPUT_SIZE\n",
        "        self.strides = np.array(YOLO_STRIDES)\n",
        "        self.classes = read_class_names(TRAIN_CLASSES)\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
        "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
        "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
        "\n",
        "        self.annotations = self.load_annotations(dataset_type)\n",
        "        self.num_samples = len(self.annotations)\n",
        "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
        "        self.batch_count = 0\n"
      ],
      "metadata": {
        "id": "yffHbtMhnBTa"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   def load_annotations(self, dataset_type):\n",
        "        final_annotations = []\n",
        "        with open(self.annot_path, 'r') as f:\n",
        "            txt = f.readlines()\n",
        "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
        "        np.random.shuffle(annotations)\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            # fully parse annotations\n",
        "            line = annotation.split()\n",
        "            image_path, index = \"\", 1\n",
        "            for i, one_line in enumerate(line):\n",
        "                if not one_line.replace(\",\",\"\").isnumeric():\n",
        "                    if image_path != \"\": image_path += \" \"\n",
        "                    image_path += one_line\n",
        "                else:\n",
        "                    index = i\n",
        "                    break\n",
        "            if not os.path.exists(image_path):\n",
        "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
        "\n",
        "            final_annotations.append([image_path, line[index:]])\n",
        "\n",
        "        return final_annotations"
      ],
      "metadata": {
        "id": "eOdwvUrKnGZb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.train_input_size = random.choice([self.train_input_sizes])\n",
        "            self.train_output_sizes = self.train_input_size // self.strides\n",
        "\n",
        "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
        "\n",
        "            batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "\n",
        "            batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            num = 0\n",
        "            if self.batch_count < self.num_batchs:\n",
        "                while num < self.batch_size:\n",
        "                    index = self.batch_count * self.batch_size + num\n",
        "                    if index >= self.num_samples: index -= self.num_samples\n",
        "                    annotation = self.annotations[index]\n",
        "                    image, bboxes = self.parse_annotation(annotation)\n",
        "                    label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
        "\n",
        "                    batch_image[num, :, :, :] = image\n",
        "                    batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
        "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
        "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
        "                    batch_sbboxes[num, :, :] = sbboxes\n",
        "                    batch_mbboxes[num, :, :] = mbboxes\n",
        "                    batch_lbboxes[num, :, :] = lbboxes\n",
        "                    num += 1\n",
        "                self.batch_count += 1\n",
        "                batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
        "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
        "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
        "\n",
        "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
        "            else:\n",
        "                self.batch_count = 0\n",
        "                np.random.shuffle(self.annotations)\n",
        "                raise StopIteration\n"
      ],
      "metadata": {
        "id": "0dmAxjdUnG09"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def random_horizontal_flip(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            _, w, _ = image.shape\n",
        "            image = image[:, ::-1, :]\n",
        "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_crop(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
        "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
        "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
        "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
        "\n",
        "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
        "\n",
        "        return image, bboxes"
      ],
      "metadata": {
        "id": "72FewNIpnTVg"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def random_translate(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
        "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
        "\n",
        "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
        "            image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
        "\n",
        "        return image, bboxes"
      ],
      "metadata": {
        "id": "VI7BV5HFnXYh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def parse_annotation(self, annotation):\n",
        "\n",
        "        image_path = annotation[0]\n",
        "        image = cv2.imread(image_path)\n",
        "            \n",
        "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
        "\n",
        "        if self.data_aug:\n",
        "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image, bboxes = image_preprocess(np.copy(image), [self.train_input_size, self.train_input_size], np.copy(bboxes))\n",
        "        return image, bboxes\n",
        "\n",
        "    def preprocess_true_boxes(self, bboxes):\n",
        "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
        "                           5 + self.num_classes)) for i in range(3)]\n",
        "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(3)]\n",
        "        bbox_count = np.zeros((3,))\n"
      ],
      "metadata": {
        "id": "BPv75ky-nbB0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        for bbox in bboxes:\n",
        "            bbox_coor = bbox[:4]\n",
        "            bbox_class_ind = bbox[4]\n",
        "\n",
        "            onehot = np.zeros(self.num_classes, dtype=np.float)\n",
        "            onehot[bbox_class_ind] = 1.0\n",
        "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
        "            deta = 0.01\n",
        "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
        "\n",
        "            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
        "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n",
        "\n",
        "            iou = []\n",
        "            exist_positive = False\n",
        "            for i in range(3):\n",
        "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
        "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
        "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
        "\n",
        "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
        "                iou.append(iou_scale)\n",
        "                iou_mask = iou_scale > 0.3\n",
        "\n",
        "                if np.any(iou_mask):\n",
        "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
        "\n",
        "                    label[i][yind, xind, iou_mask, :] = 0\n",
        "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
        "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
        "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
        "\n",
        "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
        "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
        "                    bbox_count[i] += 1\n",
        "\n",
        "                    exist_positive = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Y0U_jm_NnhpY",
        "outputId": "cd4b7537-4de4-4c45-bf82-380d427af58b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-3d9f25446f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbbox_coor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbbox_class_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0monehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bboxes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "            if not exist_positive:\n",
        "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
        "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
        "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
        "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
        "\n",
        "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
        "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
        "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
        "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
        "                \n",
        "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
        "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
        "                bbox_count[best_detect] += 1\n",
        "\n",
        "        label_sbbox, label_mbbox, label_lbbox = label\n",
        "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
        "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "JJPfZHGVnoWq",
        "outputId": "c3fc2124-a1f5-4cd4-c3ee-5575a5e8cd86"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-24fafcec0f0c>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    label_sbbox, label_mbbox, label_lbbox = label\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pGLvT7bBnv7d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}