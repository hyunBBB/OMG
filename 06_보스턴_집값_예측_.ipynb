{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06. 보스턴 집값 예측 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunBBB/OMG/blob/main/06_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A7%91%EA%B0%92_%EC%98%88%EC%B8%A1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NHj_1QNZblBu"
      },
      "outputs": [],
      "source": [
        "\"\"\"## DNN(MLP) 모델을 이용한 보스턴 집값 데이터 셋 회귀 분석\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "# 이걸 스텝원에다가 하는거임 아래에다가"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"* Step 1. Inptu tensor 와 Target tensor 준비(훈련데이터)\"\"\"\n",
        "\n",
        "# TODO\n",
        "# 1. import 한 boston_housing API를 이용하여 boston_housing 데이터 셋을 다운로드\n",
        "boston_housing_url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz'\n",
        "dataset_path = tf.keras.utils.get_file(\"/content/boston_housing.data\", boston_housing_url)\n",
        "dataset_path\n",
        "# 이건 안ㅆ더 되나봄\n"
      ],
      "metadata": {
        "id": "XVuQJ6l8bvSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "689d9f7c-ed57-446a-ff22-f097931c673b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/boston_housing.data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"* Step 2. 데이터의 전처리 \"\"\"\n",
        "\n",
        "# TODO\n",
        "# mean = train_data.mean(), std = train_data.std()\n",
        "# 1. train 데이터의 feature 별 평균값, 표준편차 값을 이용하여 정규화 작업을 진행 각 엑스값에서 평균값빼고 그고 하면 됨.\n",
        "#  정규화는 z = (x-mean)/std\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean  \n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NOrxY7Fob0gi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gEyFamSKOnl",
        "outputId": "aa7d874e-918f-47c8-c3ca-cab7ce6fa6c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"* Step 3. DNN(MLP) 모델 디자인\"\"\"\n",
        "\n",
        "# TODO\n",
        "# 1. Sequential API를 이용하여 boston_housing 데이터 셋을 분석 하기 위한 MLP 모델을 디자인 seq열어서 에드에드 하면되고.\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "ANFlSL9Nb3KP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이게 쌤이 하신거임\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(64, activation = 'relu', input_shape=(train_data.shape[1], )))\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dense(1)) # 집값하나만 하려고하는거니까 1이 들어가야함."
      ],
      "metadata": {
        "id": "Hr6qi6d4J61t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# model형태를 볼 수 있음. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbw6maIlKqe9",
        "outputId": "1327e2d6-c150-475b-b014-8afa121d14b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                896       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"* Step 4. 모델의 학습 정보 설정\"\"\"\n",
        "\n",
        "# TODO\n",
        "# 1. tf.keras.Model 객체의 compile 메서드를 이용하여 학습을 위한 정보들을 설정\n",
        "#   - optimizer\n",
        "#   - loss\n",
        "#   - metrics : 체점 기준인 MAE 로 설정\n",
        "\n",
        "import numpy as np\n",
        "k=4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "all_mae_histores = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # 검증 데이터 분리\n",
        "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
        "    # 훈련 데이터 분리\n",
        "    partial_train_data = np.concatenate([train_data[:i*num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:i*num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "U8kQ86ilb4oX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebcbc0d-9da6-4254-bee3-b0a0b57b6c4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쌤이 하신거\n",
        "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])"
      ],
      "metadata": {
        "id": "wpCnMo6XK-99"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"* Step 5. 모델에 input, target 데이터 연결 후 학습\"\"\"\n",
        "\n",
        "# TODO\n",
        "# 1. tf.keras.Model 객체의 fit 메서드를 이용하여 모델을 학습하세요\n",
        "#   - fit 메서드의 verbose=2 로 설정 하세요\n",
        "\n",
        "model = build_model()\n",
        "history = model.fit(partial_train_data,\n",
        "                    partial_train_targets, validation_data=(val_data, val_targets), \n",
        "                   epochs=num_epochs, batch_size=1, verbose=2)\n",
        "\n",
        "mae_history = history.history['val_mean_absolute_error']\n",
        "all_mae_histories.append(mae_history)\n",
        "\n",
        "val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 2)\n",
        "all_scores.append(val_mae)\n"
      ],
      "metadata": {
        "id": "dVuv4hS3b6Eg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "112fcc35-f4c5-41df-b421-18610dc8b113"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "303/303 - 1s - loss: 391.2737 - mae: 17.7371 - val_loss: 343.3365 - val_mae: 15.7443 - 975ms/epoch - 3ms/step\n",
            "Epoch 2/100\n",
            "303/303 - 1s - loss: 128.3422 - mae: 8.6765 - val_loss: 123.9350 - val_mae: 7.3319 - 515ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "303/303 - 1s - loss: 50.7650 - mae: 4.7734 - val_loss: 89.4310 - val_mae: 6.0765 - 515ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "303/303 - 1s - loss: 37.5266 - mae: 4.0209 - val_loss: 70.0984 - val_mae: 5.3413 - 507ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "303/303 - 0s - loss: 30.5634 - mae: 3.5804 - val_loss: 59.5455 - val_mae: 4.8254 - 493ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "303/303 - 0s - loss: 26.6664 - mae: 3.2783 - val_loss: 53.2153 - val_mae: 4.4410 - 466ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "303/303 - 1s - loss: 24.0396 - mae: 3.0863 - val_loss: 46.6355 - val_mae: 4.1980 - 513ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "303/303 - 1s - loss: 22.3032 - mae: 2.9770 - val_loss: 43.7605 - val_mae: 3.9739 - 505ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "303/303 - 0s - loss: 20.5778 - mae: 2.8524 - val_loss: 42.0187 - val_mae: 3.8873 - 459ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "303/303 - 0s - loss: 19.3081 - mae: 2.7962 - val_loss: 39.5141 - val_mae: 3.7228 - 451ms/epoch - 1ms/step\n",
            "Epoch 11/100\n",
            "303/303 - 0s - loss: 18.3191 - mae: 2.6603 - val_loss: 38.5931 - val_mae: 3.6503 - 446ms/epoch - 1ms/step\n",
            "Epoch 12/100\n",
            "303/303 - 0s - loss: 17.6745 - mae: 2.6060 - val_loss: 36.7408 - val_mae: 3.5602 - 456ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "303/303 - 0s - loss: 16.8179 - mae: 2.5298 - val_loss: 34.0566 - val_mae: 3.3764 - 498ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "303/303 - 1s - loss: 16.0870 - mae: 2.4877 - val_loss: 34.5833 - val_mae: 3.4399 - 545ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "303/303 - 0s - loss: 15.5575 - mae: 2.4093 - val_loss: 33.5644 - val_mae: 3.3446 - 473ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "303/303 - 1s - loss: 15.1385 - mae: 2.3554 - val_loss: 31.9823 - val_mae: 3.1910 - 546ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "303/303 - 1s - loss: 14.4721 - mae: 2.3011 - val_loss: 31.0292 - val_mae: 3.1323 - 515ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "303/303 - 0s - loss: 14.0435 - mae: 2.2817 - val_loss: 30.0592 - val_mae: 3.1115 - 466ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "303/303 - 0s - loss: 13.4865 - mae: 2.1996 - val_loss: 29.9007 - val_mae: 3.1576 - 429ms/epoch - 1ms/step\n",
            "Epoch 20/100\n",
            "303/303 - 0s - loss: 12.7068 - mae: 2.1996 - val_loss: 29.8040 - val_mae: 3.0505 - 495ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "303/303 - 0s - loss: 12.6516 - mae: 2.1862 - val_loss: 29.2573 - val_mae: 3.0238 - 440ms/epoch - 1ms/step\n",
            "Epoch 22/100\n",
            "303/303 - 0s - loss: 12.8882 - mae: 2.1427 - val_loss: 27.3467 - val_mae: 2.9016 - 492ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "303/303 - 0s - loss: 12.3410 - mae: 2.1174 - val_loss: 26.8654 - val_mae: 2.8971 - 499ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "303/303 - 1s - loss: 12.0350 - mae: 2.0771 - val_loss: 29.0252 - val_mae: 3.1052 - 506ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "303/303 - 0s - loss: 11.9744 - mae: 2.0891 - val_loss: 26.6574 - val_mae: 2.9523 - 497ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "303/303 - 0s - loss: 11.7013 - mae: 2.0581 - val_loss: 25.5453 - val_mae: 2.8860 - 499ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "303/303 - 0s - loss: 11.4290 - mae: 2.0905 - val_loss: 25.8518 - val_mae: 2.8850 - 450ms/epoch - 1ms/step\n",
            "Epoch 28/100\n",
            "303/303 - 1s - loss: 11.0723 - mae: 2.0165 - val_loss: 25.1928 - val_mae: 2.8857 - 512ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "303/303 - 1s - loss: 11.1564 - mae: 2.0266 - val_loss: 23.3193 - val_mae: 2.7810 - 505ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "303/303 - 0s - loss: 11.0909 - mae: 2.0254 - val_loss: 23.9872 - val_mae: 2.8086 - 451ms/epoch - 1ms/step\n",
            "Epoch 31/100\n",
            "303/303 - 0s - loss: 10.8521 - mae: 1.9987 - val_loss: 23.0077 - val_mae: 2.7365 - 452ms/epoch - 1ms/step\n",
            "Epoch 32/100\n",
            "303/303 - 1s - loss: 10.6420 - mae: 2.0010 - val_loss: 23.5760 - val_mae: 2.7504 - 526ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "303/303 - 0s - loss: 10.6318 - mae: 1.9856 - val_loss: 22.3675 - val_mae: 2.7334 - 498ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "303/303 - 0s - loss: 10.3238 - mae: 1.9940 - val_loss: 21.8742 - val_mae: 2.6522 - 448ms/epoch - 1ms/step\n",
            "Epoch 35/100\n",
            "303/303 - 0s - loss: 10.4047 - mae: 1.9732 - val_loss: 22.3662 - val_mae: 2.6749 - 455ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "303/303 - 0s - loss: 10.0613 - mae: 1.9498 - val_loss: 21.5209 - val_mae: 2.6543 - 495ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "303/303 - 1s - loss: 10.4379 - mae: 1.9437 - val_loss: 21.5012 - val_mae: 2.6757 - 500ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "303/303 - 0s - loss: 9.9381 - mae: 1.9612 - val_loss: 20.4028 - val_mae: 2.5762 - 447ms/epoch - 1ms/step\n",
            "Epoch 39/100\n",
            "303/303 - 0s - loss: 10.0609 - mae: 1.9357 - val_loss: 20.8379 - val_mae: 2.6029 - 467ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "303/303 - 0s - loss: 9.7320 - mae: 1.8921 - val_loss: 19.7975 - val_mae: 2.5581 - 456ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "303/303 - 1s - loss: 9.7234 - mae: 1.8920 - val_loss: 21.4948 - val_mae: 2.8953 - 510ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "303/303 - 0s - loss: 9.7982 - mae: 1.9089 - val_loss: 20.5184 - val_mae: 2.5905 - 492ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "303/303 - 0s - loss: 9.5992 - mae: 1.8865 - val_loss: 20.2813 - val_mae: 2.6375 - 466ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "303/303 - 0s - loss: 9.4890 - mae: 1.8839 - val_loss: 19.8862 - val_mae: 2.5987 - 494ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "303/303 - 0s - loss: 9.2141 - mae: 1.8942 - val_loss: 19.5786 - val_mae: 2.5727 - 456ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "303/303 - 0s - loss: 9.2317 - mae: 1.8903 - val_loss: 20.0724 - val_mae: 2.5905 - 450ms/epoch - 1ms/step\n",
            "Epoch 47/100\n",
            "303/303 - 0s - loss: 9.1677 - mae: 1.8973 - val_loss: 20.2167 - val_mae: 2.6217 - 498ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "303/303 - 0s - loss: 9.4241 - mae: 1.8919 - val_loss: 19.3480 - val_mae: 2.5586 - 461ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "303/303 - 1s - loss: 9.0091 - mae: 1.8657 - val_loss: 19.5896 - val_mae: 2.6083 - 501ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "303/303 - 0s - loss: 9.0279 - mae: 1.8738 - val_loss: 18.5808 - val_mae: 2.5345 - 447ms/epoch - 1ms/step\n",
            "Epoch 51/100\n",
            "303/303 - 0s - loss: 8.8033 - mae: 1.8204 - val_loss: 19.3215 - val_mae: 2.5856 - 443ms/epoch - 1ms/step\n",
            "Epoch 52/100\n",
            "303/303 - 0s - loss: 8.8797 - mae: 1.8250 - val_loss: 17.9732 - val_mae: 2.5024 - 450ms/epoch - 1ms/step\n",
            "Epoch 53/100\n",
            "303/303 - 0s - loss: 8.7128 - mae: 1.8213 - val_loss: 19.0002 - val_mae: 2.5699 - 493ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "303/303 - 0s - loss: 8.6042 - mae: 1.8535 - val_loss: 17.9657 - val_mae: 2.4897 - 451ms/epoch - 1ms/step\n",
            "Epoch 55/100\n",
            "303/303 - 0s - loss: 8.7102 - mae: 1.8671 - val_loss: 18.1340 - val_mae: 2.4893 - 499ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "303/303 - 1s - loss: 8.5538 - mae: 1.7994 - val_loss: 17.1808 - val_mae: 2.4632 - 509ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "303/303 - 0s - loss: 8.4192 - mae: 1.8203 - val_loss: 17.4010 - val_mae: 2.4802 - 448ms/epoch - 1ms/step\n",
            "Epoch 58/100\n",
            "303/303 - 0s - loss: 8.5440 - mae: 1.8064 - val_loss: 19.0451 - val_mae: 2.6565 - 458ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "303/303 - 0s - loss: 8.6746 - mae: 1.8205 - val_loss: 17.3000 - val_mae: 2.4947 - 440ms/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "303/303 - 0s - loss: 8.2642 - mae: 1.7822 - val_loss: 17.6353 - val_mae: 2.5314 - 447ms/epoch - 1ms/step\n",
            "Epoch 61/100\n",
            "303/303 - 0s - loss: 8.4659 - mae: 1.8053 - val_loss: 17.6135 - val_mae: 2.4989 - 447ms/epoch - 1ms/step\n",
            "Epoch 62/100\n",
            "303/303 - 0s - loss: 8.2133 - mae: 1.8005 - val_loss: 16.8273 - val_mae: 2.4669 - 499ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "303/303 - 1s - loss: 8.2492 - mae: 1.7852 - val_loss: 16.4055 - val_mae: 2.4288 - 501ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "303/303 - 0s - loss: 8.1696 - mae: 1.7727 - val_loss: 17.3925 - val_mae: 2.5269 - 460ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "303/303 - 0s - loss: 8.0106 - mae: 1.7423 - val_loss: 17.3322 - val_mae: 2.5021 - 468ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "303/303 - 0s - loss: 8.4119 - mae: 1.7657 - val_loss: 16.5649 - val_mae: 2.5095 - 494ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "303/303 - 0s - loss: 8.0116 - mae: 1.7417 - val_loss: 16.4100 - val_mae: 2.4420 - 478ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "303/303 - 1s - loss: 7.7942 - mae: 1.7598 - val_loss: 15.5577 - val_mae: 2.3828 - 504ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "303/303 - 0s - loss: 7.7261 - mae: 1.7665 - val_loss: 16.1461 - val_mae: 2.4333 - 482ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "303/303 - 1s - loss: 7.8351 - mae: 1.7770 - val_loss: 16.3219 - val_mae: 2.4418 - 519ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "303/303 - 0s - loss: 7.8789 - mae: 1.7498 - val_loss: 16.8346 - val_mae: 2.5003 - 486ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "303/303 - 0s - loss: 8.0092 - mae: 1.7330 - val_loss: 16.3378 - val_mae: 2.5215 - 454ms/epoch - 1ms/step\n",
            "Epoch 73/100\n",
            "303/303 - 0s - loss: 7.9626 - mae: 1.7408 - val_loss: 15.6115 - val_mae: 2.4113 - 480ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "303/303 - 0s - loss: 7.9121 - mae: 1.7208 - val_loss: 15.7776 - val_mae: 2.4059 - 445ms/epoch - 1ms/step\n",
            "Epoch 75/100\n",
            "303/303 - 0s - loss: 7.9236 - mae: 1.7201 - val_loss: 16.2180 - val_mae: 2.4401 - 460ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "303/303 - 0s - loss: 7.6493 - mae: 1.7391 - val_loss: 16.3712 - val_mae: 2.4523 - 452ms/epoch - 1ms/step\n",
            "Epoch 77/100\n",
            "303/303 - 0s - loss: 7.7874 - mae: 1.7094 - val_loss: 15.8907 - val_mae: 2.5200 - 462ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "303/303 - 1s - loss: 7.4224 - mae: 1.7331 - val_loss: 15.6574 - val_mae: 2.4140 - 527ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "303/303 - 1s - loss: 7.6952 - mae: 1.6933 - val_loss: 15.7827 - val_mae: 2.4459 - 517ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "303/303 - 1s - loss: 7.7496 - mae: 1.7345 - val_loss: 16.5828 - val_mae: 2.5582 - 501ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "303/303 - 0s - loss: 7.7793 - mae: 1.7074 - val_loss: 15.1523 - val_mae: 2.3840 - 444ms/epoch - 1ms/step\n",
            "Epoch 82/100\n",
            "303/303 - 0s - loss: 7.6133 - mae: 1.6848 - val_loss: 15.3546 - val_mae: 2.4024 - 469ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "303/303 - 0s - loss: 7.6006 - mae: 1.7146 - val_loss: 15.6800 - val_mae: 2.4129 - 433ms/epoch - 1ms/step\n",
            "Epoch 84/100\n",
            "303/303 - 0s - loss: 7.6817 - mae: 1.7064 - val_loss: 15.2821 - val_mae: 2.4096 - 497ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "303/303 - 0s - loss: 7.5004 - mae: 1.7145 - val_loss: 14.8564 - val_mae: 2.4133 - 497ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "303/303 - 1s - loss: 7.0777 - mae: 1.6974 - val_loss: 14.8772 - val_mae: 2.4408 - 514ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "303/303 - 0s - loss: 7.1828 - mae: 1.6750 - val_loss: 15.3922 - val_mae: 2.5481 - 488ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "303/303 - 1s - loss: 7.5795 - mae: 1.6938 - val_loss: 14.7434 - val_mae: 2.4127 - 518ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "303/303 - 0s - loss: 7.3590 - mae: 1.6978 - val_loss: 13.9149 - val_mae: 2.3611 - 462ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "303/303 - 1s - loss: 7.2188 - mae: 1.6886 - val_loss: 14.5796 - val_mae: 2.4183 - 506ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "303/303 - 0s - loss: 7.1446 - mae: 1.6821 - val_loss: 14.1553 - val_mae: 2.3865 - 499ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "303/303 - 0s - loss: 7.1252 - mae: 1.6659 - val_loss: 15.8492 - val_mae: 2.6092 - 472ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "303/303 - 0s - loss: 7.1418 - mae: 1.6749 - val_loss: 14.1536 - val_mae: 2.4221 - 448ms/epoch - 1ms/step\n",
            "Epoch 94/100\n",
            "303/303 - 0s - loss: 7.0794 - mae: 1.6680 - val_loss: 14.1295 - val_mae: 2.3809 - 452ms/epoch - 1ms/step\n",
            "Epoch 95/100\n",
            "303/303 - 0s - loss: 7.0071 - mae: 1.6923 - val_loss: 14.2922 - val_mae: 2.4745 - 492ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "303/303 - 0s - loss: 7.0171 - mae: 1.6586 - val_loss: 14.0421 - val_mae: 2.4185 - 440ms/epoch - 1ms/step\n",
            "Epoch 97/100\n",
            "303/303 - 0s - loss: 6.9979 - mae: 1.7045 - val_loss: 14.0298 - val_mae: 2.3845 - 444ms/epoch - 1ms/step\n",
            "Epoch 98/100\n",
            "303/303 - 0s - loss: 7.0853 - mae: 1.6469 - val_loss: 13.6987 - val_mae: 2.3516 - 496ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "303/303 - 0s - loss: 7.0663 - mae: 1.6399 - val_loss: 13.6676 - val_mae: 2.3248 - 462ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "303/303 - 1s - loss: 7.0120 - mae: 1.6024 - val_loss: 13.4326 - val_mae: 2.4243 - 502ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e7561443e580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                    epochs=num_epochs, batch_size=1, verbose=2)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmae_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mall_mae_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_mean_absolute_error'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쌤이 하신거\n",
        "history = model.fit( x = train_data, y = train_labels,\n",
        "                    epochs = 100, batch_size = 1,\n",
        "                    validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "rPlto7UTLM1v",
        "outputId": "7d8f6938-b208-4698-db55-e89034f0c793"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1c75b67042fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 쌤이 하신거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit( x = train_data, y = train_labels,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     validation_split = 0.2)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"* 모델 제출 \"\"\"\n",
        "\n",
        "# 학습된 모델을 제출하기 위한 코드 입니다. 수정하지 마세요\n",
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "QhxF8YlDb7Ki"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}